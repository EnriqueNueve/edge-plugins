#!/usr/bin/env python3
# ANL:waggle-license
#  This file is part of the Waggle Platform.  Please see the file
#  LICENSE.waggle.txt for the legal details of the copyright and software
#  license.  For more details on the Waggle project, visit:
#           http://www.wa8.gl
# ANL:waggle-license
import argparse
import os
import time
import json
import cv2
import numpy as np
import sys
import waggle.plugin
from pathlib import Path


healthcheck_file = Path('/run/healthcheck')


def read_model_file(path, desc):
    model = read_model_file_using_ext(path, desc)
    # NOTE: Did not work in Waggle 2.9.0; needs investigation
    # Use OpenCL
    model.setPreferableBackend(cv2.dnn.DNN_BACKEND_DEFAULT)
    model.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL)
    return model


def read_model_file_using_ext(path, desc):
    _, ext = os.path.splitext(path)
    if 'pb' in ext:
        return cv2.dnn.readNetFromTensorflow(path, desc)
    if 'caffemodel' in ext:
        return cv2.dnn.readNetFromCaffe(path, desc)
    raise ValueError(f'Model extension {ext} not recognized.')


def read_classes_file(path):
    classes = {}

    with open(path, 'r') as file:
        for line in file:
            sp = line.strip().split(' ')
            classes[int(sp[0])] = sp[1]

    return classes


def detect_objects(img_blob, cvNet, classes, confidence=0.3, img_rows=1, img_cols=1):
    cvNet.setInput(img_blob)
    cvOut = cvNet.forward()

    output = {}
    for detection in cvOut[0, 0, :, :]:
        score = float(detection[2])
        if score > confidence:
            class_index = int(detection[1])
            class_name = classes[class_index]
            if class_name not in output:
                output[class_name] = {}

            detection_index = len(output[class_name].keys())
            left = int(detection[3] * img_cols)
            top = int(detection[4] * img_rows)
            right = int(detection[5] * img_cols)
            bottom = int(detection[6] * img_rows)

            output[class_name][detection_index] = (
                left, top, right, bottom
            )
    return output


def print_detected_objects(detected_objects):
    for detected_object in detected_objects:
        print('%s was found at' % (detected_object,))
        for _, rect in detected_objects[detected_object].items():
            left, top, right, bottom = rect
            x = left + ((right - left) / 2.)
            y = top + ((bottom - top) / 2.)
            print('    x:%5d, y:%5d' % (x, y))
        print('Total: %s %d' % (detected_object, len(
            detected_objects[detected_object].keys())))


def open_video_capture(input):
    capture = cv2.VideoCapture(input)

    if not capture.isOpened():
        raise RuntimeError(f'could not open input {input}')

    return capture


parser = argparse.ArgumentParser()
parser.add_argument('--debug', action='store_true')
parser.add_argument('--input', default='http://cam_bottom_live:8090/live')
args = parser.parse_args()

config = {
    'source': 'bottom',
    'model': 'models/ssd_mobilenet_coco.pb',
    'model_desc': 'models/ssd_mobilenet_coco.pbtxt',
    'classes': 'models/ssd_mobilenet_coco.classes',
    'input_scale': 0.00784,
    'input_size': (300, 300),
    'input_mean_subtraction': (127.5, 127.5, 127.5),
    'input_channel_order': 'RGB',
    'detection_interval': 300,  # every 5 mins
    'sampling_interval': -1,  # None, by default
    'detection_confidence': 0.3,  # least detection confidence
}

print(f'opening input {args.input}')
capture = open_video_capture(args.input)

print(f'loading model and model config')
cvNet = read_model_file(config['model'], config['model_desc'])
classes = read_classes_file(config['classes'])
confidence = float(config.get('detection_confidence', 0.3))
swapRB = 'RGB' in config['input_channel_order'].upper()

if not args.debug:
    plugin = waggle.plugin.Plugin()

while True:
    _, img = capture.read()

    if img is None:
        time.sleep(0.1)
        continue

    print('received image', flush=True)

    img_blob = cv2.dnn.blobFromImage(
        img,
        config['input_scale'],
        config['input_size'],
        config['input_mean_subtraction'],
        swapRB=swapRB,
        crop=False
    )

    detected_objects = detect_objects(
        img_blob,
        cvNet,
        classes,
        confidence=confidence,
        img_rows=img.shape[0],
        img_cols=img.shape[1]
    )

    cars = detected_objects.get('car', {})
    people = detected_objects.get('person', {})

    count_car = len(cars)
    count_person = len(people)

    print(f'cars={count_car} pedestrians={count_person}')

    if not args.debug:
        plugin.add_measurement({
            'sensor_id': 0x3001,
            'parameter_id': 1,
            'value': count_car,
        })

        plugin.add_measurement({
            'sensor_id': 0x3001,
            'parameter_id': 2,
            'value': count_person,
        })

        plugin.publish_measurements()

    # healthcheck_file will be checked and removed by docker HEALTHCHECK
    healthcheck_file.touch()
